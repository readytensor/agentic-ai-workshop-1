{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c23ca8",
   "metadata": {},
   "source": [
    "# Agentic AI Workshop — Part 1: Basic LLM Calls, Streaming, and Chat\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Text-in → Text-out with the OpenAI Python SDK\n",
    "- Text → Image generation\n",
    "- Text → Audio (TTS)\n",
    "- A minimal Gradio UI for an LLM call\n",
    "- Streaming responses\n",
    "- A simple multi‑turn chat\n",
    "\n",
    "> **Prereqs**\n",
    "> - `pip install openai gradio`  \n",
    "> - Set your API key in the environment as `OPENAI_API_KEY` (recommended).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d5e41",
   "metadata": {},
   "source": [
    "# %%capture\n",
    "# If needed, uncomment to install:\n",
    "# !pip install --upgrade openai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, base64, time\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "# Expect OPENAI_API_KEY to be in env; you can also set it explicitly here (not recommended).\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-...\"\n",
    "\n",
    "client = OpenAI()  # Uses OPENAI_API_KEY from environment\n",
    "print(\"Client ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbc0ab",
   "metadata": {},
   "source": [
    "# --- 1) Basic text generation\n",
    "prompt = \"Write a friendly, two-sentence definition of Retrieval-Augmented Generation.\"\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt,\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacf0af",
   "metadata": {},
   "source": [
    "# --- 2) Image generation (Text → Image)\n",
    "# Saves a PNG called 'workshop_image.png'.\n",
    "img = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=\"Flat illustration of a helpful robot librarian fetching knowledge from a bookshelf labeled 'RAG'\",\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "b64 = img.data[0].b64_json\n",
    "png_bytes = base64.b64decode(b64)\n",
    "with open(\"workshop_image.png\", \"wb\") as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "print(\"Saved image to workshop_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266cac2",
   "metadata": {},
   "source": [
    "# --- 3) Audio generation (Text → Speech)\n",
    "# Saves an MP3 called 'workshop_audio.mp3'.\n",
    "# The 'voice' options may vary; try 'alloy', 'verse', or others supported by your account.\n",
    "speech = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Welcome to the Agentic AI workshop! Today we will build with RAG and LLM workflows.\"\n",
    ")\n",
    "\n",
    "audio_bytes = speech.read()\n",
    "with open(\"workshop_audio.mp3\", \"wb\") as f:\n",
    "    f.write(audio_bytes)\n",
    "\n",
    "print(\"Saved audio to workshop_audio.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972ed68",
   "metadata": {},
   "source": [
    "# --- 4) Gradio UI: single-turn LLM call\n",
    "\n",
    "def generate_reply(user_text):\n",
    "    r = client.responses.create(model=\"gpt-4o-mini\", input=user_text)\n",
    "    return r.output_text\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_reply,\n",
    "    inputs=gr.Textbox(label=\"Ask the model\"),\n",
    "    outputs=gr.Textbox(label=\"Model reply\"),\n",
    "    title=\"Basic LLM Call\",\n",
    "    description=\"Single-turn text → text using OpenAI Responses API.\"\n",
    ")\n",
    "\n",
    "# Uncomment to launch locally\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04185af1",
   "metadata": {},
   "source": [
    "# --- 5) Streaming example (console print)\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def response_stream(**kwargs):\n",
    "    stream = client.responses.stream(**kwargs)\n",
    "    try:\n",
    "        yield stream\n",
    "    finally:\n",
    "        stream.close()\n",
    "\n",
    "print(\"Streaming tokens:\")\n",
    "with response_stream(model=\"gpt-4o-mini\", input=\"Explain RAG in one paragraph.\") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\", flush=True)\n",
    "        elif event.type == \"response.completed\":\n",
    "            print(\"\\n\\n[done]\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d0115",
   "metadata": {},
   "source": [
    "# --- 6) Multi-turn Chat with Gradio\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a concise teaching assistant helping users learn Agentic AI fundamentals.\"\n",
    "\n",
    "def chat_bot(history, user_msg):\n",
    "    # Convert Gradio history to messages\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    for turn in history:\n",
    "        user, assistant = turn\n",
    "        if user:\n",
    "            messages.append({\"role\": \"user\", \"content\": user})\n",
    "        if assistant:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "\n",
    "    r = client.chat.completions.create(  # Chat Completions kept for familiarity\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    reply = r.choices[0].message.content\n",
    "    history.append((user_msg, reply))\n",
    "    return history, \"\"\n",
    "\n",
    "with gr.Blocks(title=\"Multi‑Turn Chat\") as chat_app:\n",
    "    gr.Markdown(\"### Multi‑Turn Chat (Gradio)\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"Ask something about agentic AI...\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def clear_fn():\n",
    "        return []\n",
    "\n",
    "    msg.submit(chat_bot, [chatbot, msg], [chatbot, msg])\n",
    "    clear.click(clear_fn, [], [chatbot])\n",
    "\n",
    "# Uncomment to launch locally\n",
    "# chat_app.launch()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
