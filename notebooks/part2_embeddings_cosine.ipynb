{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c03ab5",
   "metadata": {},
   "source": [
    "\n",
    "# Agentic AI Workshop 1\n",
    "# Part 2: Embeddings & Similarity Metrics (No Vector DB Yet)\n",
    "\n",
    "\n",
    "WHAT YOU'LL LEARN IN THIS NOTEBOOK:\n",
    "\n",
    "1. What are embeddings?\n",
    "   - Converting text into numerical vectors (arrays of numbers)\n",
    "   - Why embeddings capture semantic meaning, not just keywords\n",
    "   - How similar meanings result in similar vectors\n",
    "\n",
    "2. Similarity Metrics\n",
    "   - Cosine Similarity: Measures the angle between vectors (most common)\n",
    "   - Euclidean Similarity: Measures the distance between vectors\n",
    "   - When to use each metric\n",
    "\n",
    "3. Document Retrieval Without a Database\n",
    "   - How to find the most relevant documents for a query\n",
    "   - Why this is the foundation of RAG (Retrieval-Augmented Generation)\n",
    "   - Understanding the difference between keyword search and semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52117393-8dd3-4da7-93ce-1776deeaab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from helpers import load_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d09f1a-2064-431a-88b6-183dafcdc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and verify API keys\n",
    "load_env(api_key_type=\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69dc1a9-46a3-47d0-8432-8be55b762ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs directory\n",
    "OUTPUTS_DIR = './../outputs/'\n",
    "os.makedirs(OUTPUTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93c18a-654b-4db2-8aad-0e74611e0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()  # Uses OPENAI_API_KEY from environment\n",
    "print(\"Client ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    # Returns an array of shape (N, D)\n",
    "    resp = client.embeddings.create(model=model, input=texts)\n",
    "    return np.array([d.embedding for d in resp.data], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809418f-7700-42c2-ab90-0b3c734825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Cosine similarity: measures angle between vectors (range: -1 to 1)\"\"\"\n",
    "    a = a / (np.linalg.norm(a) + 1e-8)\n",
    "    b = b / (np.linalg.norm(b) + 1e-8)\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    \"\"\"Cosine distance: 1 minus cosine similarity (range: 0 to 2)\"\"\"\n",
    "    return 1 - cosine_similarity(a, b)\n",
    "\n",
    "def euclidean_similarity(a, b):\n",
    "    \"\"\"Euclidean similarity: inverse of Euclidean distance (normalized to 0-1 range)\"\"\"\n",
    "    distance = np.linalg.norm(a - b)\n",
    "    # Convert distance to similarity (smaller distance = higher similarity)\n",
    "    # Using exponential decay for better visualization\n",
    "    similarity = np.exp(-distance / 10)\n",
    "    return float(similarity)\n",
    "\n",
    "# Dictionary of available similarity functions\n",
    "SIMILARITY_METRICS = {\n",
    "    \"cosine\": cosine_similarity,\n",
    "    \"euclidean\": euclidean_similarity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83aefa-46e7-4fcc-826a-68c0a73a0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot results\n",
    "def plot_similarity_scores(df, query, metric_name, save_filename=None):\n",
    "    \"\"\"\n",
    "    Create a horizontal bar chart showing document similarity scores.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'title' and 'similarity' columns (sorted descending)\n",
    "        query: The query string used for comparison\n",
    "        metric_name: Name of the similarity metric used\n",
    "        save_filename: Optional filename to save the chart (without path)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.barh(df[\"title\"], df[\"similarity\"], color='#1db1c1')\n",
    "    plt.xlabel(f'{metric_name.title()} Similarity Score', fontsize=12)\n",
    "    plt.ylabel('Document', fontsize=12)\n",
    "    plt.title(f'Document Relevance to Query ({metric_name.title()} Similarity)\\n\"{query}\"', \n",
    "              fontsize=14, pad=20)\n",
    "    plt.xlim(0, 1)  # Normalized similarity range\n",
    "    plt.gca().invert_yaxis()  # Highest score at top\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # Add score labels at the end of each bar\n",
    "    for bar, score in zip(bars, df[\"similarity\"]):\n",
    "        plt.text(bar.get_width() + 0.01,  # x position (slightly after bar end)\n",
    "                 bar.get_y() + bar.get_height()/2,  # y position (center of bar)\n",
    "                 f'{score:.3f}',  # score with 3 decimal places\n",
    "                 va='center',  # vertical alignment\n",
    "                 fontsize=10,\n",
    "                 fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the chart if filename provided\n",
    "    if save_filename:\n",
    "        chart_path = os.path.join(OUTPUTS_DIR, save_filename)\n",
    "        plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Chart saved to: {chart_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6621fe-e816-4758-aa50-5076cace0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents with more distinct topics\n",
    "# Normally, you would read these from some knowledge base (docs can be pdfs, markdown, txt, etc.)\n",
    "documents = [\n",
    "    {\n",
    "        \"title\": \"Deep Learning\",\n",
    "        \"content\": \"Deep learning uses neural networks with multiple layers to learn hierarchical representations from data. It excels at tasks like image recognition and natural language processing.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Time Series Forecasting\",\n",
    "        \"content\": \"Time series forecasting estimates future values based on historical patterns. Common methods include ARIMA, exponential smoothing, and recurrent neural networks for sequential data.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Model Deployment\",\n",
    "        \"content\": \"Model deployment involves packaging trained models into production systems. This includes creating APIs, containerization with Docker, and monitoring model performance in real-time.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Feature Engineering\",\n",
    "        \"content\": \"Feature engineering transforms raw data into meaningful inputs for machine learning models. Techniques include scaling, encoding categorical variables, and creating interaction terms.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Anomaly Detection\",\n",
    "        \"content\": \"Anomaly detection identifies unusual patterns that deviate from normal behavior. Applications include fraud detection, network security, and quality control in manufacturing.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284d0be-c896-4fec-a801-76eae8bfac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION: Choose similarity metric\n",
    "# Options: \"\"cosine or \"euclidean\"\n",
    "SIMILARITY_METRIC = \"cosine\"  # Change this to \"euclidean\" to try different metric\n",
    "\n",
    "# Get the similarity function\n",
    "similarity_func = SIMILARITY_METRICS[SIMILARITY_METRIC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5d2bb-597d-47a4-a5d8-efc7a5c635fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: Query about deployment\n",
    "\n",
    "query1 = \"What's the best way to put my trained model into production?\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"EXAMPLE 1 - Using {SIMILARITY_METRIC.upper()} similarity\")\n",
    "print(\"=\"*80)\n",
    "print(f\"QUERY: {query1}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract content for embeddings\n",
    "doc_contents = [doc[\"content\"] for doc in documents]\n",
    "doc_titles = [doc[\"title\"] for doc in documents]\n",
    "\n",
    "# Get embeddings for Example 1\n",
    "doc_embeddings = get_embeddings(doc_contents)\n",
    "query1_embedding = get_embeddings([query1])[0]\n",
    "\n",
    "# Compute similarities\n",
    "scores1 = [similarity_func(query1_embedding, e) for e in doc_embeddings]\n",
    "\n",
    "# Create dataframe\n",
    "df1 = pd.DataFrame({\n",
    "    \"title\": doc_titles,\n",
    "    \"document\": doc_contents,\n",
    "    \"similarity\": scores1\n",
    "}).sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "print(f\"\\nDocument Similarity Scores using {SIMILARITY_METRIC.upper()} (sorted by relevance):\\n\")\n",
    "print(df1[[\"title\", \"similarity\"]].to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Plot Example 1\n",
    "plot_similarity_scores(df1, query1, SIMILARITY_METRIC, \n",
    "                      save_filename=f'similarity_example1_{SIMILARITY_METRIC}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436c74e-bd3b-4f6e-bd9b-d6669c3a2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: Query about temporal data\n",
    "\n",
    "query2 = \"How can I predict stock prices for the next quarter?\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"EXAMPLE 2 - Using {SIMILARITY_METRIC.upper()} similarity\")\n",
    "print(\"=\"*80)\n",
    "print(f\"QUERY: {query2}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get embeddings for Example 2 (reuse doc_embeddings)\n",
    "query2_embedding = get_embeddings([query2])[0]\n",
    "\n",
    "# Compute similarities\n",
    "scores2 = [similarity_func(query2_embedding, e) for e in doc_embeddings]\n",
    "\n",
    "# Create dataframe\n",
    "df2 = pd.DataFrame({\n",
    "    \"title\": doc_titles,\n",
    "    \"document\": doc_contents,\n",
    "    \"similarity\": scores2\n",
    "}).sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "print(f\"\\nDocument Similarity Scores using {SIMILARITY_METRIC.upper()} (sorted by relevance):\\n\")\n",
    "print(df2[[\"title\", \"similarity\"]].to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Plot Example 2\n",
    "plot_similarity_scores(df2, query2, SIMILARITY_METRIC, \n",
    "                      save_filename=f'similarity_example2_{SIMILARITY_METRIC}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b1a778-8bf0-43e1-b05e-74476212a59d",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### EXERCISE 1: Experiment with Different Queries (Beginner)\n",
    "----------------------------------------------------------\n",
    "Try these queries and observe which documents rank highest:\n",
    "\n",
    "1. \"How do I prepare my data before training a model?\"\n",
    "2. \"What techniques help identify fraudulent transactions?\"\n",
    "3. \"I want to forecast sales for the next month\"\n",
    "\n",
    "### EXERCISE 2: Add Your Own Documents (Intermediate)\n",
    "----------------------------------------------------------\n",
    "Add 2-3 more documents to the collection on AI/ML topics of your choice.\n",
    "Examples: \"Reinforcement Learning\", \"Natural Language Processing\", \"Computer Vision\"\n",
    "\n",
    "Then create a query that should match YOUR new documents best.\n",
    "\n",
    "\n",
    "### EXERCISE 3: Compare Different Similarity Metrics (Intermediate)\n",
    "----------------------------------------------------------\n",
    "We've been using cosine similarity, but there are other ways to measure similarity!\n",
    "\n",
    "Other metrics to try:\n",
    "- \"dot_product\": Direct multiplication of vectors (fast!)\n",
    "- \"manhattan\": Sum of absolute differences (robust to outliers)\n",
    "\n",
    "Your tasks:\n",
    "1. Implement and try other metrics and analyze the differences in results\n",
    "2. Re-run both examples and observe the results\n",
    "3. Document your findings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b33af-fbd6-48e9-8b6f-3b9c2abb6cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
