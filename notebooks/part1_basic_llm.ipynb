{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI Workshop — Part 1: Basic LLM Calls, Streaming, and Chat\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Text-in → Text-out with the OpenAI Python SDK\n",
    "- Text → Image generation\n",
    "- Text → Audio (TTS)\n",
    "- A minimal Gradio UI for an LLM call\n",
    "- Streaming responses\n",
    "- A simple multi‑turn chat\n",
    "\n",
    "> **Prereqs**\n",
    "> - `pip install openai gradio`  \n",
    "> - Set your API key in the environment as `OPENAI_API_KEY` (recommended).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os, io, base64, time\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "# Load environment variables from .env file\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from helpers import load_environment, get_env_var\n",
    "\n",
    "# Load environment variables\n",
    "load_environment()\n",
    "print(\"Environment variables loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Please set your OPENAI_API_KEY in the .env file\n"
     ]
    }
   ],
   "source": [
    "# Verify API key is loaded\n",
    "api_key = get_env_var('OPENAI_API_KEY')\n",
    "if not api_key or api_key == 'your_openai_api_key_here':\n",
    "    print(\"⚠️  Please set your OPENAI_API_KEY in the .env file\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API key found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect OPENAI_API_KEY to be in env; you can also set it explicitly here (not recommended).\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-...\"\n",
    "\n",
    "client = OpenAI()  # Uses OPENAI_API_KEY from environment\n",
    "print(\"Client ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Basic text generation\n",
    "prompt = \"Write a friendly, two-sentence definition of Retrieval-Augmented Generation.\"\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Image generation (Text → Image)\n",
    "# Saves a PNG called 'workshop_image.png'.\n",
    "img = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"Flat illustration of a helpful robot librarian fetching knowledge from a bookshelf labeled 'RAG'\",\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "b64 = img.data[0].b64_json\n",
    "png_bytes = base64.b64decode(b64)\n",
    "with open(\"workshop_image.png\", \"wb\") as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "print(\"Saved image to workshop_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Audio generation (Text → Speech)\n",
    "# Saves an MP3 called 'workshop_audio.mp3'.\n",
    "# The 'voice' options may vary; try 'alloy', 'verse', or others supported by your account.\n",
    "speech = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Welcome to the Agentic AI workshop! Today we will build with RAG and LLM workflows.\"\n",
    ")\n",
    "\n",
    "with open(\"workshop_audio.mp3\", \"wb\") as f:\n",
    "    f.write(speech.content)\n",
    "\n",
    "print(\"Saved audio to workshop_audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Gradio UI: single-turn LLM call\n",
    "\n",
    "def generate_reply(user_text):\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[{\"role\": \"user\", \"content\": user_text}]\n",
    "    )\n",
    "    return r.choices[0].message.content\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_reply,\n",
    "    inputs=gr.Textbox(label=\"Ask the model\"),\n",
    "    outputs=gr.Textbox(label=\"Model reply\"),\n",
    "    title=\"Basic LLM Call\",\n",
    "    description=\"Single-turn text → text using OpenAI Chat Completions API.\"\n",
    ")\n",
    "\n",
    "# Uncomment to launch locally\n",
    "# demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Streaming example (console print)\n",
    "\n",
    "print(\"Streaming tokens:\")\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain RAG in one paragraph.\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n[done]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6) Multi-turn Chat with Gradio\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a concise teaching assistant helping users learn Agentic AI fundamentals.\"\n",
    "\n",
    "def chat_bot(history, user_msg):\n",
    "    # Convert Gradio history to messages\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    for turn in history:\n",
    "        user, assistant = turn\n",
    "        if user:\n",
    "            messages.append({\"role\": \"user\", \"content\": user})\n",
    "        if assistant:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    reply = r.choices[0].message.content\n",
    "    history.append((user_msg, reply))\n",
    "    return history, \"\"\n",
    "\n",
    "with gr.Blocks(title=\"Multi‑Turn Chat\") as chat_app:\n",
    "    gr.Markdown(\"### Multi‑Turn Chat (Gradio)\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"Ask something about agentic AI...\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def clear_fn():\n",
    "        return []\n",
    "\n",
    "    msg.submit(chat_bot, [chatbot, msg], [chatbot, msg])\n",
    "    clear.click(clear_fn, [], [chatbot])\n",
    "\n",
    "# Uncomment to launch locally\n",
    "# chat_app.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
